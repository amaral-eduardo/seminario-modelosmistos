---
title: ''
output: pdf_document
---
## 4.7 Interpretando estimativas de parâmetros no modelo final

Consideramos os resultados gerados ajuste do modelo 4.2 usando method = "REML"

# 4.7.1 Estimativas de parâmetros de efeito fixo
```{r, echo=FALSE, message=FALSE, error=FALSE}
class<-nlmeU::SIIdata
attach(class)
library(nlme)

# Model 4.1.
model4.1.fit <- lme(mathgain ~ 1, random = ~ 1 | schoolid/classid,
                    class, method = "REML") # Wilkinson–Rogers notation
# ou
model <- lme(mathgain ~ 1, random =list( ~ 1 | schoolid, ~ 1 | classid),
             class, method = "REML")


ef<- random.effects(model4.1.fit)

ef2<- random.effects(model)

#########################

# Model 4.1A.
model4.1A.fit <- lme(mathgain ~ 1, random = ~1 | schoolid,
                     data = class, method = "REML")

ob<- anova(model4.1.fit, model4.1A.fit)

# 0.5*pchisq(ob[2,8], df = 0, lower.tail = F) + 0.5*pchisq(ob[2,8], df = 1, lower.tail = F)

###########################

# Model 4.2.
model4.2.fit <- lme(mathgain ~ mathkind + sex + minority + ses,
                    random = ~1 | schoolid/classid, class,
                    na.action = "na.omit", method = "REML")
# summary(model4.2.fit)$tTable


# Model 4.1: ML estimation with lme().
model4.1.ml.fit <- lme(mathgain ~ 1, random = ~1 | schoolid/classid,
                       class, method = "ML")
# Model 4.2: ML estimation with lme().
model4.2.ml.fit <- lme(mathgain ~ mathkind + sex + minority + ses,
                       random = ~1 | schoolid/classid, class,
                       na.action = "na.omit", method = "ML")
ob<- anova(model4.1.ml.fit, model4.2.ml.fit)

###################

# Model 4.3.
model4.3.fit <- update(model4.2.fit, fixed =
                         ~ mathkind + sex + minority + ses + 
                         yearstea + mathprep + mathknow)

#####################

# Model 4.4.
model4.4.fit <- update(model4.2.fit, fixed = ~ mathkind + 
                         sex + minority+ ses + housepov)

model4.4.ml.fit <- update(model4.2.fit, fixed = ~ mathkind + sex + minority+ ses +
                            housepov, method = "ML")
```



```{r}
knitr::kable(summary(model4.2.fit)$tTable, align = 'c')
```
Com base nos resultados do Modelo 4.2, vemos que o ganho na pontuação em matemática na primavera da primeira série (MATHGAIN) está significativamente relacionado à:

* MATHKIND = pontuação do aluno em matemática na primavera do ano do jardim de infância
* MINORITY = variável indicadora (0 = aluno não minoritário, 1 = aluno minoritário)
* SES = Situação socioeconômica do aluno

O efeito fixo estimado de SEXO (mulheres em relação a homens: 0 = menino, 1 = menina) é o único efeito fixo não significativo no Modelo 4.2 (p = 0,45). O efeito fixo estimado da pontuação de matemática do jardim de infância, MATHKIND, na pontuação de desempenho em matemática na primeira série, MATHGAIN, é negativo (-0,47), sugerindo que os alunos com pontuações mais altas em matemática na primavera de seu ano de jardim de infância têm um ganho menor previsto em desempenho em matemática na primavera da primeira série, após o ajuste para os efeitos de outras covariáveis (ou seja, SEX, MINORITY e SES). Ou seja, os alunos que vão bem em matemática no jardim de infância não vão melhorar tanto no próximo ano quanto os alunos que vão mal no jardim de infância. Prevê-se que os alunos MINORITY têm uma pontuação média de MATHGAIN 8,25 unidades menor do que os alunos não minoritários, após o ajuste para os efeitos de outras covariáveis. Além disso, prevê-se que alunos com SES mais alto tenham maior ganho de desempenho em matemática do que alunos com SES mais baixo, controlando os efeitos das outras covariáveis no modelo.

# 4.7.2 Estimativas de parâmetros de covariância

```{r}
knitr::kable(VarCorr(model4.2.fit), align = 'c')
```
$$\upsilon_k  \overset{iid}{\sim} N(0, \sigma_{int:school}^{2}), \ \ \upsilon_{j|k} \overset{iid}{\sim} N(0, \sigma_{int:clasroom}^{2})\ \ \mathrm{e} \ \ \varepsilon_{ij} \overset{iid}{\sim} N(0, \sigma ^2)$$
$$\widehat{\sigma}_{int:school}^2 = 75.2, \ \ \widehat{\sigma}_{int:clasroom}^2 = 83.28 \ \ e \ \ \widehat{\sigma}^2 = 734.56$$

A adição das covariáveis de efeitos fixos ao nível de estudante no Modelo 4.1 (isto é Modelo 4.2) reduziu a variância residual estimada em cerca de 29\% (variância residual estimada = 1028.23 no Modelo 4.1, contra 734.56 no Modelo 4.2). As estimativas dos componentes de variância no nível da sala de aula e da escola também foram reduzidas pela adição dos efeitos fixos associados às covariáveis ao nível de aluno, embora não substancialmente (a variância estimada no nível da sala de aula foi reduzida em cerca de 17,4\%, e a estimativa da variância no nível escola foi reduzida em cerca de 2,9\%). Isso sugere que as quatro covariáveis no nível do aluno estão efetivamente explicando algumas das variações aleatórias nos valores de resposta nos diferentes níveis do conjunto de dados, especialmente no nível do aluno (como esperado). A magnitude dos componentes de variância no Modelo 4.2 (e os testes qui-quadrado significativos relatados para os componentes de variância) sugere que ainda há variação aleatória inexplicada nos valores da resposta em todos os três níveis deste conjunto de dados. Neste ponto, efeitos fixos associados a covariáveis adicionais podem ser adicionados ao modelo, para ver se eles ajudam a explicar a variação aleatória nos diferentes níveis dos dados

## 4.8 Estimando os Coeficientes de Correlação Intraclasse (ICCs)

No contexto de um modelo hierárquico de três níveis com intercepto aleatório, o coeficiente de correlação intraclasse (ICC) é uma medida que descreve a similaridade (ou homogeneidade) das respostas observadas dentro de um determinado cluster. Para cada nível de agrupamento (por exemplo, sala de aula ou escola), um ICC pode ser definido como uma função dos componentes de variação. Para abreviar nesta seção, representamos a variância dos efeitos aleatórios associados às escolas como $\sigma_s^2$ (em vez de $\sigma_{int:school}^2$), e a variância dos efeitos aleatórios associados às salas de aula aninhadas nas escolas como $\sigma_c^2$ (em vez de $\sigma_{int:classroom}^2$). O ICC em nível de escola é definido como a proporção da variação aleatória total nas respostas observadas (o denominador em (2)) devido à variância dos efeitos escolares aleatórios (o numerador em (2)):
$$ICC_{school} = \frac{\sigma_{s}^{2}}{\sigma_{s}^{2} + \sigma_{c}^{2} + \sigma^{2}}$$
O valor do $ICC_{school}$ é alto se a variação aleatória total for dominada pela variância dos efeitos aleatórios da escola. Em outras palavras, a $ICC_{school}$ é alta se as pontuações MATHGAIN dos alunos na mesma escola são relativamente homogêneas, mas as pontuações MATHGAIN entre as escolas tendem a variar amplamente.

Da mesma forma, o ICC em nível de sala de aula é definido como a proporção da variação aleatória total (o denominador em (3)) devido à variação aleatória entre escolas e entre salas de aula (o numerador em (3)):

$$ICC_{classroom} = \frac{\sigma_{s}^{2} + \sigma_{c}^{2}}{\sigma_{s}^{2} + \sigma_{c}^{2} + \sigma^{2}}$$

Este ICC é alto se houver pouca variação nas respostas dos alunos na mesma sala de aula ($\sigma^2$ é baixo) em comparação com a variação aleatória total.

 O ICC pode ser calculado a partir de um modelo sem efeitos fixos de outras covariáveis (por exemplo, Modelo 4.1) ou para um modelo incluindo esses efeitos fixos (por exemplo, Modelos 4.2 ou 4.3). Em ambos os casos, podemos obter os ICCs das estimativas dos componentes de variância rotulados ou da matriz de correlação marginal estimada, conforme descrito anteriormente.

```{r}
knitr::kable(VarCorr(model4.1.fit), align = 'c')
```

$$ICC_{school} = \frac{77.49202}{77.49202+99.22751+1028.23396}=0.0643$$
$$ICC_{classroom} = \frac{ 77.49202+99.22751}{ 77.49202+99.22751+1028.23396}=0.1467$$

As observações sobre os alunos na mesma escola são modestamente correlacionadas, enquanto as observações sobre os alunos na mesma sala de aula têm uma correlação um pouco mais alta.

```{r}
knitr::kable(VarCorr(model4.2.fit), align = 'c')
```

$$ICC_{school} = \frac{75.20343}{75.20343+83.28461+734.56509}=0.0842$$

$$ICC_{classroom} = \frac{75.20343+83.28461}{75.20343+83.28461+734.56509}=0.1775$$

As observações sobre os alunos na mesma escola são modestamente correlacionadas, enquanto as observações sobre os alunos na mesma sala de aula têm uma correlação um pouco mais alta.


Para ilustrar ainda mais os cálculos do ICC, consideramos a matriz marginal de variância-covariância $V_k$ implícita no Modelo 4.1 para uma escola hipotética, k, com duas salas de aula, com a primeira sala com dois alunos e a segunda com três alunos. Primeiro, vamos escrever o modelo incondicional, Modelo 4.1, na forma matricial.
$$V_k=Var(MATHGAIN)_k=Z_kD_kZT_k+R_k$$
$$V_k = 
\begin{pmatrix}
\sigma_s^2 + \sigma_c^2 + \sigma^2 &\sigma_s^2 + \sigma_c^2  &\sigma_s^2  &\sigma_s^2  &\sigma_s^2 \\ 
\sigma_s^2 + \sigma_c^2 &\sigma_s^2 + \sigma_c^2 + \sigma^2  &\sigma_s^2  &\sigma_s^2  &\sigma_s^2 \\ 
\sigma_s^2 &\sigma_s^2  &\sigma_s^2 + \sigma_c^2 + \sigma^2  &\sigma_s^2 + \sigma_c^2  &\sigma_s^2 + \sigma_c^2 \\ 
\sigma_s^2 &\sigma_s^2  &\sigma_s^2 + \sigma_c^2 &\sigma_s^2 + \sigma_c^2 + \sigma^2  &\sigma_s^2 + \sigma_c^2 \\ 
\sigma_s^2 &\sigma_s^2  &\sigma_s^2 + \sigma_c^2 &\sigma_s^2 + \sigma_c^2  &\sigma_s^2 + \sigma_c^2 + \sigma^2 
\end{pmatrix}$$

As primeiras duas linhas e colunas desta matriz correspondem às observações sobre os dois alunos da primeira sala de aula, e as últimas três linhas e colunas correspondem às observações sobre os três alunos da segunda classe.

A matriz de correlação marginal correspondente para essas observações pode ser calculada dividindo todos os elementos na matriz Vk pela variância total de uma dada observação, $[Var(y_{ijk}) = \sigma_s^2 + \sigma_c^2 + \sigma^2]$ conforme mostrado abaixo, os ICCs definidos em (2) e (3) podem ser facilmente identificados nesta matriz de correlação implícita:

$$V_k(corr) = \begin{pmatrix}
1 &\frac{\sigma_{s}^{2} + \sigma_{c}^{2}}{\sigma_{s}^{2} + \sigma_{c}^{2} + \sigma^{2}}  &\frac{\sigma_{s}^{2}}{\sigma_{s}^{2} + \sigma_{c}^{2} + \sigma^{2}}  &\frac{\sigma_{s}^{2}}{\sigma_{s}^{2} + \sigma_{c}^{2} + \sigma^{2}}  &\frac{\sigma_{s}^{2}}{\sigma_{s}^{2} + \sigma_{c}^{2} + \sigma^{2}} \\ 
\frac{\sigma_{s}^{2} + \sigma_{c}^{2}}{\sigma_{s}^{2} + \sigma_{c}^{2} + \sigma^{2}} &1  &\frac{\sigma_{s}^{2}}{\sigma_{s}^{2} + \sigma_{c}^{2} + \sigma^{2}}  &\frac{\sigma_{s}^{2}}{\sigma_{s}^{2} + \sigma_{c}^{2} + \sigma^{2}}  &\frac{\sigma_{s}^{2}}{\sigma_{s}^{2} + \sigma_{c}^{2} + \sigma^{2}} \\ 
\frac{\sigma_{s}^{2}}{\sigma_{s}^{2} + \sigma_{c}^{2} + \sigma^{2}} &\frac{\sigma_{s}^{2}}{\sigma_{s}^{2} + \sigma_{c}^{2} + \sigma^{2}}  &1  &\frac{\sigma_{s}^{2} + \sigma_{c}^{2}}{\sigma_{s}^{2} + \sigma_{c}^{2} + \sigma^{2}}  &\frac{\sigma_{s}^{2} + \sigma_{c}^{2}}{\sigma_{s}^{2} + \sigma_{c}^{2} + \sigma^{2}} \\ 
\frac{\sigma_{s}^{2}}{\sigma_{s}^{2} + \sigma_{c}^{2} + \sigma^{2}} &\frac{\sigma_{s}^{2}}{\sigma_{s}^{2} + \sigma_{c}^{2} + \sigma^{2}}  &\frac{\sigma_{s}^{2} + \sigma_{c}^{2}}{\sigma_{s}^{2} + \sigma_{c}^{2} + \sigma^{2}}  &1  &\frac{\sigma_{s}^{2} + \sigma_{c}^{2}}{\sigma_{s}^{2} + \sigma_{c}^{2} + \sigma^{2}} \\ 
\frac{\sigma_{s}^{2}}{\sigma_{s}^{2} + \sigma_{c}^{2} + \sigma^{2}} &\frac{\sigma_{s}^{2}}{\sigma_{s}^{2} + \sigma_{c}^{2} + \sigma^{2}}  &\frac{\sigma_{s}^{2} + \sigma_{c}^{2}}{\sigma_{s}^{2} + \sigma_{c}^{2} + \sigma^{2}}  &\frac{\sigma_{s}^{2} + \sigma_{c}^{2}}{\sigma_{s}^{2} + \sigma_{c}^{2} + \sigma^{2}}  &1 
\end{pmatrix}$$

```{r}
 options(width = 90)
 library(mgcv)

 Vs<- extract.lme.cov2(model4.1.fit,data=class, start.level=1)
 knitr::kable(round(Vs$V[[1]],1), align = 'c')
```

As matrizes marginais de variância-covariância para observações sobre alunos em qualquer escola teriam a mesma estrutura, mas seriam de dimensões diferentes, dependendo do número de alunos dentro da escola. As observações sobre os alunos em escolas diferentes terão covariância zero, porque são consideradas independentes umas das outras.

Observe na saída da função cov2cor(), a seguir, que as observações sobre diferentes alunos na mesma sala de aula nesta escola têm uma correlação marginal estimada de 0,1467, e as observações sobre os alunos em diferentes salas de aula nesta escola têm uma correlação estimada de 0,0643. Esses resultados correspondem aos cálculos ICC iniciais com base nos componentes de variância estimados.

```{r}
knitr::kable(round(cov2cor(Vs$V[[1]]),4), align = 'c')
```

As covariáveis não são consideradas nas definições clássicas do ICC, seja com base no modelo de intercepto aleatório ou no modelo marginal; no entanto, as covariáveis podem ser facilmente acomodadas na estrutura do modelo misto em qualquer configuração de modelo. O ICC pode ser calculado a partir de um modelo sem efeitos fixos de outras covariáveis (por exemplo, Modelo 4.1) ou para um modelo incluindo esses efeitos fixos (por exemplo, Modelos 4.2 ou 4.3). Em ambos os casos, podemos obter os ICCs das estimativas dos componentes de variância rotulados ou da matriz de correlação marginal estimada, conforme descrito anteriormente.

##  4.9 Cálculo de valores preditos
Considerando as estimativas para os efeitos fixos no Modelo 4.2, podemos escrever uma fórmula para os valores predistos condicionais de MATHGAIN para um aluno em uma determinada sala de aula:
```{r}
knitr::kable(summary(model4.2.fit)$tTable, align = 'c')
```

Com o modelo ajustado podemos gerar três conjuntos diferentes de valores preditos: valores preditos condicionais, incluindo os EBLUPs dos efeitos aleatórios da escola e da sala de aula, e valores preditos marginais baseados apenas nos efeitos fixos estimados. Por exemplo:

* Incluindo os EBLUPs do efeito aleatório para a escola deste aluno, $u_k$, e o efeito sala de aula aleatório para este aluno, $u_{j|k}$.

$$\widehat{MATHGAIN_{ijk}} = 282.7903 - 0.4698 \times MATHKIND_{ijk} - 1.2512 \times SEX_{ijk}$$ $$- 8.2621 \times MINORITY_{ijk} + 5.3464 \times SES_{ijk} + \widehat{u}_k + \widehat{u}_{j|k}$$

Os resíduos calculados com base nesses valores preditos condicionais devem ser usados para avaliar as suposições de normalidade e variância constante para os resíduos.

* incluindo apenas os EBLUPs do efeito efeito sala de aula aleatório para este aluno, $u_{j|k}$.

$$\widehat{MATHGAIN_{ijk}} = 282.7903 - 0.4698 \times MATHKIND_{ijk} - 1.2512 \times SEX_{ijk}$$ $$- 8.2621 \times MINORITY_{ijk} + 5.3464 \times SES_{ijk} + \widehat{u}_k$$

* baseado na distribuição marginal de MATHGAIN, para gerar valores preditos marginais

$$\widehat{MATHGAIN_{ijk}} = 282.7903 - 0.4698 \times MATHKIND_{ijk} - 1.2512 \times SEX_{ijk} - 8.2621 \times MINORITY_{ijk} + 5.3464 \times SES_{ijk}$$

```{r}
# Efeitos
ef <- ranef(model4.2.fit)
ef1 <- ef[[1]][,1];ef2<-ef[[2]][,1]

options(width=90)
pred <- predict(model4.2.fit,level=0:2)
knitr::kable(head(pred), align = 'c')
```

```{r, echo=FALSE}
dadospred <- cbind(class[schoolid=="1",c("classid","mathkind","sex",
                                         "minority","ses","mathgain")],
                   round(pred[schoolid=="1",3:5],2))
```


Considerando o primeiro aluno da escola 1 e predizendo utilizando de valores preditos condicionais.

```{r}
knitr::kable(dadospred[1,-1], align = 'c')
```


$$\widehat{MATHGAIN_{ijk}} = 282.7903 - 0.4698 \times 448 - 1.2512 \times 1 - 8.2621 1 + 5.3464 \times 0.46 + 0.4981 + 3.4025 = 69.166544$$
